---
title: "proj_test"
author: ""
date: '202X-XX-XX'
output: html_document
---

```{r setup, include=FALSE}
library(reticulate)
library(MetaBAnalysis)
knitr::opts_chunk$set(echo = TRUE)
knitr::knit_engines$set(python = reticulate::eng_python)
```

### Filter the data and run dada2:
```{r}
CollectData <- function(directory = "../Filtered_data") {
    forward <- list.files(directory, pattern = "_1.fastq.gz", full.names = TRUE)
    reverse <- list.files(directory, pattern = "_2.fastq.gz", full.names = TRUE)
    forwardC <- list.files(directory, pattern = "_1.fastq.gz", full.names = FALSE)
    reverseC <- list.files(directory, pattern = "_2.fastq.gz", full.names = FALSE)
    filtFs <- file.path(directory, "filtered", forwardC)
    filtRs <- file.path(directory, "filtered", reverseC)
    allSamples <- unique(gsub("_outFwd_1.fastq.gz|_outRev_1.fastq.gz", "", forwardC))
    output <- list(Forward = forward,
                   Reverse = reverse,
                   ForwardC = forwardC,
                   ReverseC = reverseC,
                   FiltFs = filtFs,
                   FiltRs = filtRs,
                   Samples = allSamples)
    return(output)
}

# Collect sample paths and names. Duplicate line once per primer.
primer1 <- CollectData("../Filtered_data")

OutCombine <- function(dataset, samples) { # Function that summarizes rows of forward and reverse counts in the "out"-object
  counter <- 0
    for(i in samples) {
      if (counter == 0) {
        output <- data.frame()
        counter <- counter + 1
        }
      output <- rbind(output, S2 = colSums(dataset[grepl(x = rownames(dataset), pattern = i),]))
      rownames(output)[rownames(output) == "1"] <- i
      rownames(output)[rownames(output) == "S2"] <- i
    }
  names(output) <- c("reads.in", "reads.out")
  return(output)
}

out <- dada2::filterAndTrim(primer1$Forward, primer1$FiltFs, 
                            primer1$Reverse, primer1$FiltRs,
                            maxN=0, truncQ=2, rm.phix=TRUE,
                            compress=TRUE, multithread=TRUE)

saveRDS(out, file = "out.rds")

#outCombined <- OutCombine(out, primer1$Samples) # Summarize forward and reverse for every sample

forwardCounts2 <- DadaAnalysis(primer1$FiltFs, primer1$FiltRs, justConcatenate = TRUE)
```

### Convert and modify  matrix "forwardCounts2" to DGEList "yAll":
```{r}
DFCombine <- function(dataset, samples) {
  counter <- 0
    for(i in samples) {
      if (counter == 0) {
        output <- data.frame(S2 = rowSums(dataset[, grepl(x = names(dataset), pattern = i)]))
        counter <- counter + 1
        names(output)[names(output) == "S2"] <- i
        next
        }
      output <- cbind(output, S2 = rowSums(dataset[, grepl(x = names(dataset), pattern = i)]))
      names(output)[names(output) == "S2"] <- i
      }
  return(output)
}

MakeDGEList <- function(dataset, samples, forwardSamples) { # Function that combines forward and reverse runs if reverse runs are present
  datasetDF <- as.data.frame(t(dataset))
  if(any(grepl("outRev", forwardSamples))) {
    dfAll <- DFCombine(datasetDF, samples)
    yAll <- edgeR::DGEList(dfAll)
  } else {
    yAll <- edgeR::DGEList(datasetDF)
  }
  return(yAll)
}

yAll <- MakeDGEList(forwardCounts2, primer1$Samples, primer1$ForwardC)
saveRDS(yAll, file = "yAll.rds")
```

### Export fasta-file:
```{r}
ExportFasta(yAll, "y_test.fa")
```

### BLAST-tools (Experimental):
```{r}
# blastOut <- MultiBlaster(fastaFile = "y_test.fa")
# BlastResWriter(blastOut, "y_test.out")
```

### Parse BLAST-results:
```{r}
### The following code assumes that the folder "../../Suppl_data" exists and contains the files "compact_names.csv" and
# "compact_nodes.csv. If it does not, create the folder in that location and perform the following:
# 1. $ cd Suppl_data
# 2. $ wget https://ftp.ncbi.nih.gov/pub/taxonomy/taxdmp.zip
# 3. $ unzip taxdmp.zip
# 4. $ awk -F\t '{gsub(/[^[:alnum:]]/," ", $3); if ($7 == "scientific name") {print $1 "\t" $3}}' names.dmp > compact_names.csv
# 5. $ awk -F\t '{gsub(/[^[:alnum:]]/," ", $3); print $1 "\t" $3 "\t" $5}' nodes.dmp > compact_nodes.csv
# 6. $ rm *.dmp *.prt *.txt *.zip

## load("~/Develop/eDNA/Analysis/data/compactNameDump.RData")
## load("~/Develop/eDNA/Analysis/data/compactNodeDump.RData")

GetTaxonomy <- function(searchName, nameDump, nodeDump) {
  if(grepl("\\.|'", searchName) || length(strsplit(searchName, split = " ")[[1]]) > 2) { # Look out for species with "sp.", quotations or more than two names
    searchName <- strsplit(searchName, split = " ")[[1]][1]
  }
  taxList <- c("unknown", "unknown", "unknown", "unknown", "unknown", "unknown")
  taxId <- nameDump[searchName == nameDump$V2, 1]
  if(length(taxId) == 0) { # If searchName does not hit anything
    return(taxList)
  }
  taxId <- taxId[1]
  while(taxId > 2) {
    taxId  <- nodeDump[taxId == nodeDump$V1, 2]
    taxGroup <- nodeDump[taxId == nodeDump$V1, 3]
    if(taxGroup %in% c("family", "order", "class", "phylum", "kingdom", "superkingdom")) {
      taxList[match(taxGroup, c("family", "order", "class", "phylum", "kingdom", "superkingdom"))] <- nameDump[match(taxId, nameDump$V1), 2]
    }
  }
  return(taxList)
}

BlastParse <- function(DGEList, blastRes.out, threshold = 90) {
  sequences <- data.frame(id = paste("Seq", 1:length(rownames(DGEList)), sep = "_"), seq = row.names(DGEList))
  blastResult <- read.table(blastRes.out, sep = "\t", quote = "â‚¬", stringsAsFactors = FALSE)
  blastResult$V3 <- as.numeric(blastResult$V3)
  blastResult$V3[is.na(blastResult$V3)] <- 0 # If the input file contained empty values, assign them to 0
  blastResult <- blastResult[blastResult$V3 > threshold,]
  names(blastResult) <- c("qseqid", "sseqid", "pident", "length", "mismatch", "gapopen", "qstart", "qend", "sstart", "send", "evalue", "bitscore", "staxids", "sscinames", "scomnames")
  blastResultUn <- blastResult[!duplicated(blastResult$qseqid),] # Retain only best hits
  GetFirstItem <- function(name) { # Function that returns the first of items separated by semicolons
    return(strsplit(as.character(name), split = ";")[[1]][1])
  }
  blastResultUn$staxids <- unlist(lapply(blastResultUn$staxids, GetFirstItem))
  blastResultUn$sscinames <- unlist(lapply(blastResultUn$sscinames, GetFirstItem))
  blastResultUn$scomnames <- unlist(lapply(blastResultUn$scomnames, GetFirstItem))
  taxonomy <- list()
  for(i in unique(blastResultUn$sscinames)) { # Get taxonomy locally
    print(i) # Print current taxa
    taxonomy[[i]] <- GetTaxonomy(i, nameDump = compactNameDump, nodeDump = compactNodeDump)
  }
  taxonomy <- do.call("rbind", taxonomy)
  taxonomy <- cbind(rownames(taxonomy), taxonomy)
  blastTax <- merge(blastResultUn, taxonomy, by.x = "sscinames", by.y = "V1", all.x = TRUE)
  blastTax <- blastTax[, c(2,3,4,12, 1, 16:21)]
  colnames(blastTax) <- c("id", "besthit", "identity", "e-value", "species", "family", "order", "class", "phylum", "kingdom", "superkingdom")
  seqTax <- merge(sequences, blastTax, by.x = "id", by.y = "id", all.x = TRUE)
  seqTax <- seqTax[order(as.numeric(gsub("[^0-9]+", "", seqTax$id))),]
  seqTax$family <- factor(seqTax$family)
  seqTax$order <- factor(seqTax$order)
  seqTax$class <- factor(seqTax$class)
  seqTax$phylum <- factor(seqTax$phylum)
  seqTax$kingdom <- factor(seqTax$kingdom)
  seqTax$superkingdom <- factor(seqTax$superkingdom)
  return(seqTax)
}

blastResY <- BlastParse(yAll, "y_test.out")
saveRDS(blastResY, file = "blastResY.rds")
```

### Create Summaryfiles from the BLAST-results:
```{r}
allResults <- SumRes(blastRes = blastResY, counts = yAll$counts, taxGroup = "Fish") # Summarize a list of result objects
```

### Functions:
```{r}
RenameSpecies <- function(oldName, newName, dataFrame) {
  dataFrame[grepl(oldName, dataFrame[,1]),1] <- newName
  return(dataFrame)
}

CombineSpecies <- function(species1, species2, dataFrame) {
  speciesSum <- dataFrame[grepl(species1, dataFrame[,4]),5:ncol(dataFrame)] + dataFrame[grepl(species2, dataFrame[,4]),5:ncol(dataFrame)]
  speciesSum <- cbind(dataFrame[grepl(species1, dataFrame[,4]),1:4], speciesSum)
  names(speciesSum)[1:4] <- names(dataFrame[1:4])
  dataFrame <- dataFrame[!grepl(species1, dataFrame[,4]),]
  dataFrame <- dataFrame[!grepl(species2, dataFrame[,4]),]
  dataFrame <- rbind(dataFrame, speciesSum)
  return(dataFrame)
}

QSeqGetter <- function(species_name) {
  species_seq <- paste0(">", blastResY[grepl(species_name, blastResY$species),1], "\n", blastResY[grepl(species_name, blastResY$species),2])
  writeLines(species_seq, "current_sequence.txt")
  file.edit("current_sequence.txt")
}

RemoveLowFreqSeqs <- function(dataset, threshold, subValue = 0) {
  output <- data.frame(dataset[, 1:4])
  for(column in 5:ncol(dataset)){
    ratio <- dataset[, column] / sum(dataset[, column]) * 100
    dataset[ratio < threshold, column] <- subValue
    output <- cbind(output, dataset[, column])
  }
  colnames(output) <- colnames(dataset)
  return(output)
}
```

### Curate the results:
```{r}
library(MetaBAnalysis)
{
  groupNotes <- allResults$TargetGroup
  # groupNotes <- RenameSpecies("old latin name", "new latin name", groupNotes)
  groupNotes <- groupNotes[order(rowSums(groupNotes[,-1]), decreasing = TRUE),]
  groupNotes <- cbind(Percent_all = SpeciesPercent(groupNotes), groupNotes)
  groupNotes <- cbind(Swedish = MetaBAnalysis::TranslateTaxa(groupNotes$Species), groupNotes)
  # groupNotes[grepl("latin name", groupNotes$Species),1] <- "new common name"
  groupNotes <- cbind(Notes = c(
                                # edit here to correspond to the number of species in the groupNotes-object
                                "", "", "", "", "",
                                "", "", "", "", "",
                                "", "", "", "", "",
                                "", "", "", "", ""
                                ), groupNotes) # add notes for different species
  # groupNotes <- CombineSpecies("species to be kept", "species to be absorbed", groupNotes)
  groupNotes <- groupNotes[order(rowSums(groupNotes[,-c(1, 2, 3, 4)]), decreasing = TRUE),]
  # groupNotes <- groupNotes[!grepl("drop", groupNotes$Notes),] # Drop all species that has the word "drop" in their notes
  # groupNotes <- RemoveLowFreqSeqs(groupNotes, 0.5) # remove species within samples below a threshold
  # groupNotes <- groupNotes[groupNotes$Percent_all >= 0.5,] # remove species from all samples below a threshold
  # groupNotes <- groupNotes[rowSums(groupNotes[, -c(1, 2, 3, 4)]) > 0,] # remove all species with zero counts in all samples
  groupClean <- groupNotes[,-c(1, 3)]
  columnNames <- colnames(groupClean)
  columnNames[grepl("Species", columnNames)] <- "Latin"
  # columnNames[grepl("old sample name", columnNames)] <- "new sample name"
  names(groupClean) <- columnNames
  allResults$Clean <- groupClean
}

saveRDS(allResults, "allResults.rds") # save the clean object to be used in the report
```

### Generate information about the sequences for use in report:
```{r}
library(rvest)

getRawSeqs <- function(searchFolder = "../Pre_analysis", searchPattern = "1_fastqc.html") { # Function that extracts raw forward reads from fastqc reports
  rawPaths <- list.files(path = searchFolder, pattern = searchPattern, full.names = TRUE)
  rawFiles <- lapply(rawPaths, rvest::read_html)
  getRawTable <- function(inFile) {
    inTable <- as.data.frame(rvest::html_table(inFile, fill = TRUE)[1]) # select first table in report
    outTable <- data.frame(filename = inTable[inTable$Measure == "Filename", 2], nreads = inTable[inTable$Measure == "Total Sequences", 2])
    return(outTable)
    }
  rawTables <- lapply(rawFiles, getRawTable)
  allTable <- do.call("rbind", rawTables)
  allTable$nreads <- as.numeric(allTable$nreads)
  return(allTable)
}

rawSeqsTable <- getRawSeqs()

rawSeqs <- rawSeqsTable$nreads

sum(rawSeqs)
min(rawSeqs)
max(rawSeqs)

primerSeqs <- sum(out[, 1])
primerSeqs / sum(rawSeqs) # ratio of sequences left after primer trimming and filtration

groupSeqs <- sum(groupClean[, -c(1, 2)])
groupSeqs / primerSeqs # ratio of filtered sequences belonging to target group

sampleMetaData <- list(rawSeqs = rawSeqs, primerSeqs = primerSeqs, groupSeqs = groupSeqs)
saveRDS(sampleMetaData, "sampleMetaData.rds")

sum(groupClean[1:4, -c(1, 2)]) / sum(groupClean[, -c(1, 2)]) # see what percentage of counts the top four species accounts for
```

### Generate excel-sheet with counts from "groupClean":
```{r}
library(writexl)
write_xlsx(groupClean, "projekt_xyz_sekvensantal.xlsx")
```
