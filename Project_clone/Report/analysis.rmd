---
title: "proj_test"
author: ""
date: '202X-XX-XX'
output: html_document
---

```{r setup, include=FALSE}
library(reticulate)
knitr::opts_chunk$set(echo = TRUE)
knitr::knit_engines$set(python = reticulate::eng_python)
```

### Import python-packages:
```{python}
import subprocess
import os
```

### Define inputs for the project:
```{python}
project_name = "proj_test"
primer_f = "CAYCGTGCTATGCATGCTGT" # Forward primer
primer_r = "AGGCATRTGCCAAACATGA" # Reverse primer
###
f_format = "scilife" #scilife or novo
anchored_flag = "yes" #yes or no
reads_folder = "../Data"
```

### Python functions:
```{python}
def rev_comp(sequence): # Function that takes a sequence (a string), upper or lower case, and reverse-complements it
    sequence = sequence[::-1] # Reverse the sequence
    new_seq = "" # Initialize the new sequence
    for nucleotide in sequence: # For every nucleotide/character in the sequence
        if nucleotide == "A" or nucleotide == "a":
            nucleotide = nucleotide.replace("A","T")
            nucleotide = nucleotide.replace("a","t")
            new_seq = new_seq + nucleotide
            continue
        elif nucleotide == "T" or nucleotide == "t":
            nucleotide = nucleotide.replace("T","A")
            nucleotide = nucleotide.replace("t","a")
            new_seq = new_seq + nucleotide
            continue
        elif nucleotide == "G" or nucleotide == "g":
            nucleotide = nucleotide.replace("G","C")
            nucleotide = nucleotide.replace("g","c")
            new_seq = new_seq + nucleotide
            continue
        elif nucleotide == "C" or nucleotide == "c":
            nucleotide = nucleotide.replace("C","G")
            nucleotide = nucleotide.replace("c","g")
            new_seq = new_seq + nucleotide
            continue
    return new_seq # Return the new sequence
```


### Set parameters:
```{python}
test1 = 0
test2 = 0
if anchored_flag == "no":
    regular_primer = primer_f
    reverse_primer = primer_r
    test1 = 1
elif anchored_flag == "yes":
    primer_f_rc = rev_comp(primer_f)
    primer_r_rc = rev_comp(primer_r)
    regular_primer = primer_f + "..." + primer_r_rc
    reverse_primer = primer_r + "..." + primer_f_rc
    test1 = 1
if f_format == "scilife":
    file_end1 = "_R1_001.fastq.gz"
    file_end2 = "_R1_001.fastq.gz"
    repl_from = "R1"
    repl_to = "R2"
    test2 = 1
elif f_format == "novo":
    file_end1 = "_L1_1.fq.gz"
    file_end2 = "_L2_1.fq.gz"
    repl_from = "_1.fq"
    repl_to = "_2.fq"
    test2 = 1
if test1 + test2 != 2:
    print("Please revisit your input variables. Program terminates.")
    quit()
```

### Run cutadapt and get filenames:
```{python}
sample_list = list()
reads_list = list()
for file in os.listdir(reads_folder): #For every file in folder containing reads
    if file.endswith(file_end1) or file.endswith(file_end2): #Check if file is a .fastq-read-file
        sample = file.replace(file_end1, "") #Extract sample name
        sample = sample.replace(file_end2, "") #Extract sample name
        sample_list.append(sample) #Make a list containing all the sample-names
        current_list = list([sample + "_outFwd_1.fastq.gz", sample + "_outFwd_2.fastq.gz", sample + "_outRev_1.fastq.gz", sample + "_outRev_2.fastq.gz"]) #Create filtering names and store in a list
        reads_list.append(current_list) #Store list of filterings in a list containing all filtered reads
        
        subprocess.run(["cd " + reads_folder + "; cutadapt -j 0 --max-n=0 --discard-untrimmed -g " + regular_primer + " -G " + reverse_primer + " -o " + current_list[0] + " -p " + current_list[1] + " " + file + " " + file.replace(repl_from, repl_to)], shell=True) #Run cutadapt for regular direction
        subprocess.run(["cd " + reads_folder + "; cutadapt -j 0 --max-n=0 --discard-untrimmed -g " + regular_primer + " -G " + reverse_primer + " -o " + current_list[2] + " -p " + current_list[3] + " " + file.replace(repl_from, repl_to) + " " + file], shell=True) #Run cutadapt in reverse direction
```

### Import python variables into r:
```{r}
projectName <- py$project_name
primerList <- c(py$PrimerF, py$PrimerF_rc, py$PrimerR, py$PrimerR_rc)
allSamples <- py$sample_list
allReads <- py$reads_list
```

### Filter the data and run dada2:
```{r}
library(dada2)
library(edgeR)

DadaAnalysis <- function(forward, reverse) {
  errF <- dada2::learnErrors(forward, multithread = TRUE)
  errR <- dada2::learnErrors(reverse, multithread = TRUE)
  derepsF <- dada2::derepFastq(forward)
  derepsR <- dada2::derepFastq(reverse)
  dadaF <- dada(derepsF, err = errF, multithread = TRUE)
  dadaR <- dada(derepsR, err = errR, multithread = TRUE)
  mergers <- dada2::mergePairs(dadaF, derepsF, dadaR, derepsR, verbose = TRUE)
  seqtab <- dada2::makeSequenceTable(mergers)
  seqtab.nochim <- dada2::removeBimeraDenovo(seqtab, method = "consensus", multithread = TRUE, verbose = TRUE)
  return(seqtab.nochim)
}

forward <- list.files("../Data", pattern = "_1.fastq.gz", full.names = TRUE) # Gets all the names ending with _1 with "full" path
reverse <- list.files("../Data", pattern = "_2.fastq.gz", full.names = TRUE) # Gets -"- ending with _2
forwardC <- list.files("../Data", pattern = "_1.fastq.gz", full.names = FALSE) # Gets all names ending with _1 without full path
reverseC <- list.files("../Data", pattern = "_2.fastq.gz", full.names = FALSE) # Gets -"- ending with _2
filtFs <- file.path("../Data", "filtered", forwardC) # Creates paths for (future?) filtered forward reads
filtRs <- file.path("../Data", "filtered", reverseC) # Creates paths for (future?) filtered reverse reads

OutCombine <- function(dataset, samples) { # Function that summarizes rows of forward and reverse counts in the "out"-object
  counter <- 0
    for(i in samples) {
      if (counter == 0) {
        output <- data.frame()
        counter <- counter + 1
        }
      output <- rbind(output, S2 = colSums(dataset[grepl(x = rownames(dataset), pattern = i),]))
      rownames(output)[rownames(output) == "1"] <- i
      rownames(output)[rownames(output) == "S2"] <- i
    }
  names(output) <- c("reads.in", "reads.out")
  return(output)
}

out <- dada2::filterAndTrim(forward, filtFs, reverse, filtRs,
              maxN=0, truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE # maxEE=c(2,3),

outCombined <- OutCombine(out, allSamples) # Summarize forward and reverse for every sample

forwardCounts2 <- DadaAnalysis(filtFs, filtRs)
dfForward<- as.data.frame(t(forwardCounts2))
yForward <- edgeR::DGEList(dfForward)
```

### Combine columns in "dfForward" and convert to DGEList "yAll"
```{r}
DFCombine <- function(dataset, samples) {
  counter <- 0
    for(i in samples) {
      if (counter == 0) {
        output <- data.frame(S2 = rowSums(dataset[, grepl(x = names(dataset), pattern = i)]))
        counter <- counter + 1
        names(output)[names(output) == "S2"] <- i
        next
        }
      output <- cbind(output, S2 = rowSums(dataset[, grepl(x = names(dataset), pattern = i)]))
      names(output)[names(output) == "S2"] <- i
      }
  return(output)
}

dfAll <- DFCombine(dfForward, allSamples)
yAll <- edgeR::DGEList(dfAll)
saveRDS(yAll, file = "yAll.rds")
```

### Export fasta-file:
```{r}
library(Biostrings)

ExportFasta <- function(count_data, filename) {
  seqs <- row.names(count_data)
  names(seqs) <- paste("Seq", 1:length(seqs), sep = "_")
  Biostrings::writeXStringSet(Biostrings::DNAStringSet(seqs, use.names = TRUE), filename)
  sprintf("Wrote %s sequences to %s", length(seqs), filename) 
}

ExportFasta(yAll, "y_test.fa")
```

### Parse BLAST-results:
```{r}
library(taxize)
library(gtools)

BlastParse <- function(DGEList, blastRes.out) {
  sequences <- data.frame(id = paste("Seq", 1:length(rownames(DGEList)), sep = "_"), seq = row.names(DGEList))
  blastResult <- read.table(blastRes.out, sep = "\t", quote = "'", stringsAsFactors = FALSE)
  names(blastResult) <- c("qseqid", "sseqid", "pident", "length", "mismatch", "gapopen", "qstart", "qend", "sstart", "send", "evalue", "bitscore", "staxids", "sscinames", "scomnames")
  blastResultUn <- blastResult[!duplicated(blastResult$qseqid),] # Retain only best hits
  
  # Slow down the query speed in a for loop to avoid time outs at NCBI
  taxonomy <- list()
  for(i in levels(factor(blastResultUn$sscinames))) {
    taxonomy[[i]] <- taxize::tax_name(sci = i, get = c("superkingdom", "phylum", "order", "class", "family"), db = "ncbi")
    Sys.sleep(.5)}
  taxonomy <- do.call("rbind", taxonomy)
  
  blastTax <- merge(blastResultUn, taxonomy, by.x = "sscinames", by.y = "query", all.x = TRUE)
  blastTax <- blastTax[, c(2,3,4,12, 1, 17:21)]
  names(blastTax) <- c("id", "besthit", "identity", "e-value", "species", "superkingdom", "phylum", "order", "class", "family")
  seqTax <- merge(sequences, blastTax, by.x = "id", by.y = "id", all.x = TRUE)
  seqTax$id <- as.character(seqTax$id)
  seqTax <- seqTax[mixedorder(seqTax$id),]
  seqTax$superkingdom <- factor(seqTax$superkingdom)
  seqTax$phylum <- factor(seqTax$phylum)
  seqTax$order <- factor(seqTax$order)
  seqTax$class <- factor(seqTax$class)
  seqTax$family <- factor(seqTax$family)
  return(seqTax)
}

blastResY <- BlastParse(yAll, "y_test.out")
```

### Create Summaryfiles from the BLAST-results:
```{r}
grepGroup <- grepl("Arthropoda", blastResY$phylum) # Set which group to put in "groupSummary"

genesCounts <- cbind(blastResY, yAll$counts)
summaryAll <- aggregate(genesCounts[,12:dim(genesCounts)[2]], by = list(genesCounts$species), FUN = sum)
summaryAll <- summaryAll[order(rowSums(summaryAll[,-1]), decreasing = TRUE),]
genesGroup <- blastResY[grepGroup,]
yGroup <- yAll[row.names(yAll$counts) %in% genesGroup$seq,]
genesCountsGroup <- cbind(genesGroup, yGroup$counts)
groupSummary <- aggregate(genesCountsGroup[,12:dim(genesCounts)[2]], by = list(genesCountsGroup$species), FUN=sum)
groupSummary <- groupSummary[order(rowSums(groupSummary[,-1]), decreasing = TRUE),]

saveRDS(yAll, file = "yAll.rds")
saveRDS(genes_counts, file = "genesCounts.rds")
saveRDS(groupSummary, file = "groupSummary.rds")
saveRDS(summaryAll, file = "summaryAll.rds")
```